---
title: "Simulations In-Class Project"
date: "Due October 13, 2017 at 11:59pm"
output:
  html_document


---

<style type="text/css">
.table {

    width: 80%;
    margin-left:10%; 
    margin-right:10%;
}
</style>
```{r,setup, echo=FALSE, cache=TRUE}
## numbers >= 10^5 will be denoted in scientific notation,
## and rounded to 2 digits
options(scipen = 3, digits = 3)
```




#Project Goals:


With this project we will simulate a famous probability problem. This will not require knowledge of probability or statistics but only the logic to follow the steps in order to simulate this problem. This is one way to solve problems by using the computer. 

 1. **Gambler's Ruin**: Suppose you have a bankroll of $1000 and make bets of $100 on a fair game. By simulating the outcome directly for at most 5000 iterations of the game (or hands), estimate:
    a. the probability that you have "busted" (lost all your money) by the time you have placed your one hundredth bet. 
    
```{r}
end<-function(bankroll,bet,p,n){for(i in 1:n){
  if(rbinom(1,1,p)==1){
    bankroll<-bankroll+bet}
else {bankroll<-bankroll-bet}
  if(bankroll==0) break
}
return(c(i,bankroll))
}
time_end<-matrix(replicate(1000,end(1000,100,0.5,5000)),nrow=2,byrow=F)
prob1<-sum(time_end[1,]<100)/length(time_end[1,])
prob1
```

    b. the probability that you have busted by the time you have placed your five hundredth bet by simulating the outcome directly. 

```{r}
prob2<-sum(time_end[1,]<500)/length(time_end[1,])
prob2
```

    c. the mean time you go bust, given that you go bust within the first 5000 hands.
    
```{r}
rownames(time_end)<-c("time","bankroll")
df<-data.frame(t(time_end))
bankroll0<-df[df$bankroll==0,]
mean_t<-mean(bankroll0$time)
mean_t
```

    d. the mean and variance of your bankroll after 100 hands (including busts).

```{r}
hand100<-matrix(replicate(1000,end(1000,100,0.5,100)),nrow=2,byrow=F)
df100<-data.frame(hand100)
mean( as.numeric(df100[2,]))
var(as.numeric(df100[2,]))
```

    e. the mean and variance of your bankroll after 500 hands (including busts).
    
```{r}
hand500<-matrix(replicate(1000,end(1000,100,0.5,500)),nrow=2,byrow=F)
df500<-data.frame(hand500)
mean(as.numeric(df500[2,]))
var(as.numeric(df500[2,]))
```

 
Note: you *must* stop playing if your player has gone bust. How will you handle this in the `for` loop?

2. Repeat the previous problem with betting on black in American roulette, where the probability of winning on any spin is 18/38 for an even payout.
a.
```{r}
roulette<-matrix(replicate(1000,end(1000,100,18/38,5000)),nrow=2,byrow=F)
prob3<-sum(roulette[1,]<100)/length(roulette[1,])
prob3
```
b.
```{r}
prob4<-sum(roulette[1,]<500)/length(roulette[1,])
prob4
```
c.
```{r}
rownames(roulette)<-c("time","bankroll")
dfr<-data.frame(t(roulette))
r.bankroll0<-dfr[dfr$bankroll==0,]
mean_rt<-mean(r.bankroll0$time)
mean_rt
```
d.
```{r}
r100<-matrix(replicate(1000,end(1000,100,18/38,100)),nrow=2,byrow=F)
dfr100<-data.frame(r100)
mean( as.numeric(dfr100[2,]))
var(as.numeric(dfr100[2,]))
```
e.
```{r}
r500<-matrix(replicate(1000,end(1000,100,18/38,500)),nrow=2,byrow=F)
dfr500<-data.frame(r500)
mean(as.numeric(dfr500[2,]))
var(as.numeric(dfr500[2,]))
```


3. **Markov Chains**. Suppose you have a game where the probability of winning on your first hand is 48%; each time you win, that probability goes up by one percentage point for the next game (to a maximum of 100%, where it must stay), and each time you lose, it goes back down to 48%. Assume you cannot go bust and that the size of your wager is a constant $100.
    a. Is this a fair game? Simulate one hundred thousand sequential hands to determine the size of your return. Then repeat this simulation 99 more times to get a range of values to calculate the expectation.

```{r}
prob<-function(bet,p,inc){
  p0<-p
  cbet=0
  for(i in 1:100000){
  win=2*rbinom(1,1,p)-1
  if(win==1){p=p+inc
  if(p>1){p=1}
  }
  else{p=p0}
  cbet=cbet+win*bet
  }
return(cbet)
}

p_sim<-replicate(100,prob(100,0.48,0.01))
mean(p_sim)
```

    b. Repeat this process but change the starting probability to a new value within 2% either way. Get the expected return after 100 repetitions. Keep exploring until you have a return value that is as fair as you can make it. Can you do this automatically?

```{r}
p_seq<-seq(from=0.488,to=0.490,by=0.0002)
value<-vector("double",length(p_seq))
for(i in 1:length(p_seq)){
value[i]<-mean(replicate(100,prob(100,p_seq[i],0.01)))
}
value
# For the first test, generate a sequence from 0.48 to 0.49. And the starting probability should be around 0.489 to make a relatively fair return value. Then do the second test, generate a sequence from 0.488 to 0.490. After analysing the value(-25490 -33050 -23478  46552 -13356 -13028  42510  -4120   -896   9816   3902), the starting probability should be around 0.4897 (the average of 0.4896 and 0.4898).
```

    c. Repeat again, keeping the initial probability at 48%, but this time change the probability increment to a value different from 1%. Get the expected return after 100 repetitions. Keep changing this value until you have a return value that is as fair as you can make it. 

```{r}
change<-seq(0.01,0.02,0.001)
exp<-vector("double",length(change))
for(i in 1:length(change)){
exp[i]<-mean(replicate(100,prob(100,0.48,change[i])))
}
exp
# So to make it fair, the probability increment should be around 0.012 (Because after running the code, we can get exp as (-201406 -124514  -66516  168204 1071814 2081000 2768272 5453434 7124810 7920498 8683074). To get a more accurate probability increment, generate a sequence from 0.012 to 0.013 and observe the result.
```


4. Creating a Bootstrap function. There is a particular concept called [bootstrapping]
(https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) where we can easily create 95% confidence intervals, even for complex estimators.

The steps of this process are:

  a. Draw a sample, with replacement, from your data which is the same length of your data.
  b. Calculate the statistic of interest on this boostrap sample (ie mean, variance, regression,...)
  c. Peform steps 1:2 at least 1000 times over until you have a vector of your statistics. 
  d. The lower bound of a 95% CI will be the 0.025 percentile
  e. The upper bound of a 95% CI will be the 0.975 percentile

Make a function called `boot_ci` which calculates the 95% confidence interval in this manner. 

```{r}
boot_ci<-function(data,n,stat){
  s<-matrix(NA,nrow=n,ncol=length(data))
  for(i in 1:n){
  s[i,]<-sample(data,length(data),replace=T)
  }
  interest<-apply(s,1,stat)
  lower<-quantile(interest,0.025)
  upper<-quantile(interest,0.975)
  return(c(lower,upper))
}
```

5. For problems 3b and 3c, you calculated a mean value. Because you saved these final results in a vector, use the bootstrap to estimate the variance of the return in each case for your final answer. Once you have these results, which game has the smaller variance in returns?

```{r}
b3<-replicate(100,prob(100,0.4897,0.01))
c3<-replicate(100,prob(100,0.48,0.012))
boot_ci(b3,1000,var)
boot_ci(c3,1000,var)
```
**So 3b has the smaller variance in returns**
